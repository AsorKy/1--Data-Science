{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPP5o1YEbla3b5nuWN+LV13"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cbQeKzJAY8k-"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Dates Module\n","from datetime import datetime"]},{"cell_type":"markdown","source":["#Mussing data proportion"],"metadata":{"id":"3VSsgDvIn49B"}},{"cell_type":"code","source":["from typing_extensions import dataclass_transform\n","\n","def missing_dat(data):\n","  data = pd.DataFrame(data)\n","  data_frame = pd.DataFrame({\n","      'Non-Empty Cells': data.notnull().sum(),\n","      'NaN_Values': data.isnull().sum(),\n","      '0_Values': (data == '0').sum(),\n","      '?_Values': (data == '?').sum()\n","  })\n","  data_frame['Percentage of Adequate Data'] = (1 - (data_frame['NaN_Values'] / len(data))) * 100\n","  data_frame['Percentage of Adequate Data'] = (1 - (data_frame['0_Values'] / len(data))) * 100\n","  data_frame['Percentage of Adequate Data'] = (1 - (data_frame['?_Values'] / len(data))) * 100\n","\n","  return data_frame"],"metadata":{"id":"4Ncb54XXn8AI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dates and time"],"metadata":{"id":"Dxlqb5gUZQXR"}},{"cell_type":"code","source":["def edad(cadena):\n","    birth = datetime.strptime(cadena, '%d/%m/%Y') # Fecha nacimiento\n","    prueba = datetime.strptime('09/08/2020', '%d/%m/%Y') #Fecha presentación examen\n","    return prueba.year - birth.year # Edad el día de presentación del examen\n","\n","edad('18/04/2003') # Celda de prueba"],"metadata":{"id":"rmGKKsihZSZz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Replace by the median"],"metadata":{"id":"5YSfupsiqspQ"}},{"cell_type":"code","source":["def null_classifier(dataframe):\n","  series = dataframe.isnull().sum() * 100 / dataframe.shape[0]\n","  return series.sort_values(ascending = True)"],"metadata":{"id":"46Ed2RyFIEuo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Nan_Replace_by_median(dataframe, print_percentage=False, replace_by_median=True):\n","  col_with_nuls = dataframe.columns[dataframe.isnull().any()]\n","  col_with_nuls = col_with_nuls.tolist()\n","\n","  for col in col_with_nuls:\n","    col_per = dataframe[col].value_counts(normalize = True)\n","    col_tuples = list(zip(col_per.index, col_per.values))\n","    max_tuple = max(col_tuples, key= lambda x:x[1])\n","  \n","  if print_percentage == True:\n","    for i in col_tuples:\n","      print(col_tuples[i])\n","  \n","  if replace_by_median == True:\n","    for col in col_with_nuls:\n","      dataframe[col] = dataframe[col].fillna(value = max_tuple[0])\n","  \n","  return dataframe"],"metadata":{"id":"wFL8SJ2Zquvg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#ML preprocessing"],"metadata":{"id":"8wbw8bMJ2xgi"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","from category_encoders.ordinal import OrdinalEncoder"],"metadata":{"id":"2rdbBH3z24qC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## One hot encoding\n"],"metadata":{"id":"dbF2vr3w20fS"}},{"cell_type":"code","source":["def simple_cat_one_hot(dataframe, col_list):\n","  one_hot = pd.get_dummies(dataframe, columns = col_list)"],"metadata":{"id":"YnP73ETL2xEj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Ordinal encoding"],"metadata":{"id":"IF2XY3qE3Vji"}},{"cell_type":"code","source":["# Mappings are stipulated in the form of a list of directories\n","\n","mapping = [\n","    {\"col\":\"name of the colum to transform\",\n","     \"mapping\":{\"str_1\":value_1,\"str_2\":value_2,\"str_3\":value_3}\n","     },\n","     {\"col\":\"name of the column to transform\",\n","      \"mapping\":{\"str_1\":value_1,\"str_2\":value_2,\"str_3\":value_3}\n","     }\n","]"],"metadata":{"id":"NCZS92Yw5SbZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def Ordinal_Encoder(dataframe, map=None):\n","  if map == None:\n","    encoder = OrdinalEncoder()\n","  else:\n","    encoder = OrdinalEncoder(mapping = map)\n","  transform = encoder.fit_transform(dataframe)\n","  return transform"],"metadata":{"id":"GP3faBlK3XKU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Standarization"],"metadata":{"id":"w_ru8ksM7nJQ"}},{"cell_type":"code","source":["def standar_dat(dataframe, mean=True, std=True):\n","  scaler = preprocessing.StandardScaler(with_mean=mean,with_std=std)\n","  transform = scaler.fit_transform(dataframe)\n","  return pd.DataFrame(transform)"],"metadata":{"id":"Fa-E7Gm27oXS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Outlier detection"],"metadata":{"id":"3YV2q6wtgHW7"}},{"cell_type":"code","source":["# Outliers de una unica columna\n","def outliers(dataframe, colum_name):\n","  q1 = dataframe[colum_name].quantile(0.25)\n","  q3 = dataframe[colum_name].quantile(0.75)\n","  IQR =q3-q1\n","  condition = (dataframe[colum_name] < (q1-1.5*IQR)) | (dataframe[colum_name] > (q3+1.5*IQR))\n","  outliers_data = dataframe[condition].any(axis=1)\n","  return outliers_data\n","\n","\n","# Outliers de la clase de una columna con respecto a otra columna\n","def outliers_per_col(dataframe, col_name_1, col_name_2):\n","    iqr = lambda x: x.quantile(0.75) - x.quantile(0.25)\n","    col_1_IQR = dataframe.groupby(col_name_1)[col_name_2].apply(iqr).to_dict()\n","\n","    col_1_bounds = {}\n","\n","    for group, IQR in col_1_IQR.items():\n","        col_1_bounds[group] = (dataframe.loc[dataframe[col_name_1]==group, col_name_2].quantile(0.25)-1.5*IQR,\n","                             dataframe.loc[dataframe[col_name_1]==group, col_name_2].quantile(0.75)+1.5*IQR)\n","  \n","    outliers = dataframe.loc[dataframe.apply(lambda group: \n","                (group[col_name_2] < col_1_bounds[group[col_name_1]][0]) or \n","                (group[col_name_2] > col_1_bounds[group[col_name_1]][1]), axis=1)]\n","    \n","    return outliers"],"metadata":{"id":"bCLf5nMxgG0k"},"execution_count":null,"outputs":[]}]}